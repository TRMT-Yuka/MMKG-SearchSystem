{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e59f3852-edd4-4997-b25e-a572ad94e4db",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 順位の実装  \n",
    "・アプリケーションから使用するスニペットのみ取得"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933eb6e0-0be9-486f-b472-bb1ab9612770",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### モジュール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "779a9552-efd6-4789-9405-1ed0a99ccf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\"\n",
    "# device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2bf3fad-bacc-4129-9b5f-0edb0864facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def read_bin(filename):\n",
    "    with open(filename,'rb') as bf:\n",
    "        bin_data = pickle.load(bf)\n",
    "    return bin_data\n",
    "\n",
    "def save_bin(filename,data):\n",
    "    with open(filename,'wb') as bf:\n",
    "        pickle.dump(data,bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8744b8e6-f6c4-489e-8c89-2cdc1c331aef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List,Dict\n",
    "from collections import defaultdict\n",
    "import numpy\n",
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForPreTraining,Wav2Vec2Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fa279cb-6087-4561-a12f-3c1a673daad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = str(1)\n",
    "# num = str(2)\n",
    "# num = str(3)\n",
    "# num = str(4)\n",
    "# num = str(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5da9c84-67d8-4905-a4da-149360664559",
   "metadata": {},
   "source": [
    "##### データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2abafcd8-a57b-4fe8-81a1-780e57b8aba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # =============知識グラフ\n",
    "nodes=dict()\n",
    "with open('new_data/all_BirdDBnode.tsv', mode='r', newline='', encoding='utf-8') as f:\n",
    "    for row in csv.DictReader(f, delimiter = '\\t'):\n",
    "        nodes[row[\"id\"]] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ac93244-8c20-4c96-8154-4430521c9ede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_parquet('BirdModel_remove_test/data_cross-valid/test_'+num+'.parquet')#10293\n",
    "test_index = list(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "648e5cdd-fb3d-4479-95e7-7394f4f67813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testのid一覧,英語正式名称一覧を作成\n",
    "WavDesc2Kana=read_bin('new_data/WavDesc2Kana.bin')\n",
    "name2jid=read_bin('new_data/name2jid.bin')\n",
    "tuples_bid_jid = read_bin('new_data/tuples_bid_jid.bin')\n",
    "\n",
    "test_bids = []\n",
    "for test_name in list(test[\"description\"]):\n",
    "    test_jid = name2jid[WavDesc2Kana[test_name]]\n",
    "    for bid,jid in tuples_bid_jid:\n",
    "        if jid == test_jid:\n",
    "            test_bids.append(bid)\n",
    "            break\n",
    "\n",
    "test_queries = []\n",
    "for test_bid in test_bids:\n",
    "    test_queries.append(nodes[test_bid][\"en_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47ef0c1b-f52e-41c5-b305-49a92b9382f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "if len(test_index) == len(test_bids) == len(test_queries):\n",
    "    print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf26f6ea-4d11-4cb9-af79-ef887fd37294",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test,WavDesc2Kana,name2jid,tuples_bid_jid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d22af0a-feb5-476d-8174-e0450edc7ad9",
   "metadata": {},
   "source": [
    "##### 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c75a246-737a-4376-bc0f-eb73111cfe62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============= 2つのListのCos類似度算出関数\n",
    "import torch\n",
    "\n",
    "def cos_sim(v1, v2):\n",
    "    # リストをテンソルに変換し、GPUに転送\n",
    "    min_l = min(len(v1), len(v2))\n",
    "    \n",
    "    # v1 = torch.tensor(v1[:min_l]).float().cuda()\n",
    "    # v2 = torch.tensor(v2[:min_l]).float().cuda()\n",
    "    v1 = torch.tensor(v1[:min_l], device=device, dtype=torch.float32)\n",
    "    v2 = torch.tensor(v2[:min_l], device=device, dtype=torch.float32)\n",
    "\n",
    "    # Cos類似度の計算\n",
    "    dot_product = torch.dot(v1, v2)\n",
    "    norm_v1 = torch.norm(v1)\n",
    "    norm_v2 = torch.norm(v2)\n",
    "    cos_sim = dot_product / (norm_v1 * norm_v2)\n",
    "    \n",
    "    return cos_sim.item()  # 結果をPythonのfloat型に変換して返す\n",
    "\n",
    "def to_katakana(text):\n",
    "    # kakasiオブジェクトを作成\n",
    "    kakasi_instance = kakasi()\n",
    "    kakasi_instance.setMode(\"J\", \"K\")  # J（漢字）をH（ひらがな）に変換\n",
    "    kakasi_instance.setMode(\"H\", \"K\")  # H（ひらがな）をK（カタカナ）に変換\n",
    "    \n",
    "    # カタカナに変換\n",
    "    conv = kakasi_instance.getConverter()\n",
    "    katakana_text = conv.do(text)\n",
    "    return katakana_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "261615b4-0d12-464c-88a4-6a76120c08ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#=================================================マルチモーダル検索用関数\n",
    "def concat_vecs(query,lang,Wikidata_id,inp_Svec):\n",
    "    inp_Lvec = [0]*768\n",
    "    inp_Gvec = [0]*64\n",
    "    inp_Svec = [0]*256\n",
    "\n",
    "    if query != None:\n",
    "        if lang==\"en\":\n",
    "            en_tokens = en_tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            with torch.no_grad():\n",
    "                en_model.eval()\n",
    "                output = en_model(**en_tokens)\n",
    "        else:\n",
    "            query = to_katakana(query)\n",
    "            ja_tokens = ja_tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            with torch.no_grad():\n",
    "                ja_model.eval()\n",
    "                output = ja_model(**ja_tokens)\n",
    "        inp_Lvec = output.last_hidden_state[0][0].tolist()# queryの分散表現\n",
    "\n",
    "    if Wikidata_id != None and Wikidata_id in bid2Gvec:\n",
    "        inp_Gvec = bid2Gvec[Wikidata_id]\n",
    "\n",
    "    return inp_Lvec+inp_Gvec+inp_Svec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "321dbe2d-8bef-4172-8d42-3f6488739c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(1)\n",
    "en_concat_vecs_et=read_bin('new_data/en_concat_vecs.bin')\n",
    "print(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f5154-fad2-4f78-9858-9000752624be",
   "metadata": {},
   "source": [
    "検索内リスト化関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68e63cad-22e6-40d1-a1b4-84925a3dfce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as wavfile\n",
    "\n",
    "def Vecs_tolist(vec,processor_mode):\n",
    "    out=[]\n",
    "    v=np.mean(vec,axis=1)\n",
    "    return v.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "092409d1-c506-427e-879c-3cfc87a9e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def multi_Search_topN_SLG(concat_vecs,input_v,filename,i,num):\n",
    "    max_sim=dict()\n",
    "    c2 = 0\n",
    "        \n",
    "    for bid,v in concat_vecs:\n",
    "        print('\\r%d : %d / %d' %(i,c2, len(concat_vecs)), end='')\n",
    "        c2 =  c2 + 1\n",
    "        cos_sim_value = cos_sim(input_v,v)\n",
    "        \n",
    "        if bid not in max_sim:\n",
    "            max_sim[bid] = cos_sim_value\n",
    "        else:\n",
    "            if max_sim[bid] < cos_sim_value:\n",
    "                max_sim[bid] = cos_sim_value\n",
    "    save_bin('csv_cv_'+flg+\"_\"+num+'/'+filename+'.bin',max_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3e971b-da9e-42c5-98cb-fba6620748fb",
   "metadata": {},
   "source": [
    "## input_vecs_list_ALGの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "847ddab0-5e72-4f56-aded-739636caeedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "en_model = BertModel.from_pretrained('models/en_model')\n",
    "en_tokenizer = BertTokenizer.from_pretrained('models/en_tokenizer')\n",
    "bid2Gvec=read_bin('new_data/bid2Gvec.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e5d692b-f175-42c4-9d9a-90a913462369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = str(1)\n",
    "# num = str(2)\n",
    "# num = str(3)\n",
    "# num = str(4)\n",
    "num = str(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dfb01260-cf64-46eb-a56d-650c0e123854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./models/cv5/ were not used when initializing Wav2Vec2ForPreTraining: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForPreTraining from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForPreTraining from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForPreTraining were not initialized from the model checkpoint at ./models/cv5/ and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from contextlib import redirect_stdout\n",
    "from transformers import Wav2Vec2ForPreTraining,Wav2Vec2FeatureExtractor\n",
    "\n",
    "with redirect_stdout(open(os.devnull, 'w')):#一時的に出力を無効化\n",
    "    path = \"./models/cv\"+str(num)+\"/\"\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(\"patrickvonplaten/wav2vec2-base-v2\")# Wav2Vec2Processor => Wav2Vec2FeatureExtractor\n",
    "    model = Wav2Vec2ForPreTraining.from_pretrained(path)# Wav2Vec2ForCTC => Wav2Vec2ForPreTraining\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bc12efce-60d4-4e8d-81ff-970e0dd05648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1837 / 1838SLG\n"
     ]
    }
   ],
   "source": [
    "for slg_i in range(5):\n",
    "    SLG = [(0,1,0),(0,0,1),(0,1,1),(1,0,1),(1,1,0),(1,1,1)]\n",
    "    if_S,if_L,if_G = SLG[slg_i]\n",
    "    \n",
    "    input_vecs_list = []\n",
    "    \n",
    "    # n = 10 #結果をいくつ表示するか\n",
    "    processor_mode = False #未学習の埋め込みを使用するモード\n",
    "    lang = \"en\"\n",
    "    \n",
    "    c = 0\n",
    "    \n",
    "    for i in range(len(test_index)):\n",
    "        idx = test_index[i]\n",
    "        query = None\n",
    "        Wikidata_id = None\n",
    "        print('\\r%d / %d' %(c, len(test_index)), end='')\n",
    "        c = c + 1\n",
    "        \n",
    "        if if_S == 1:\n",
    "            sample_rate, waveform = wavfile.read(\"wav/\"+str(idx)+\".wav\")\n",
    "            SVec = processor(waveform, sampling_rate=sample_rate, return_tensors=\"pt\").input_values\n",
    "            del sample_rate,waveform\n",
    "            SVec = SVec.to(torch.float32)\n",
    "            SVec = SVec.to(device)\n",
    "            with torch.no_grad():\n",
    "                model_output = model(SVec)\n",
    "                imp_SVec = model_output.projected_states.detach().cpu().numpy()\n",
    "                # imp_SVec = normalize(imp_SVec)#正規化処理を行う場合以下を実行\n",
    "                imp_SVec = Vecs_tolist(imp_SVec,processor_mode)\n",
    "        else:\n",
    "            imp_SVec = [0]*256\n",
    "    \n",
    "        if if_L == 1:\n",
    "            query = test_queries[i]\n",
    "    \n",
    "        if if_G == 1:\n",
    "            Wikidata_id = test_bids[i]\n",
    "        \n",
    "        input_vecs = concat_vecs(query,lang,Wikidata_id,imp_SVec)\n",
    "        input_vecs_list.append(input_vecs)\n",
    "    \n",
    "    flg = \"\"\n",
    "    if if_S == 1:\n",
    "        flg += \"S\"\n",
    "    if if_L == 1:\n",
    "        flg += \"L\"\n",
    "    if if_G == 1:\n",
    "        flg += \"G\"\n",
    "    \n",
    "    print(flg)\n",
    "    \n",
    "    save_bin(\"new_data_cv_SLG/input_vecs_list_\"+flg+\"_\"+num+\".bin\",input_vecs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d1b106-55c2-4c0d-bb2f-2d5dd14ac357",
   "metadata": {},
   "source": [
    "### 検索実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f3902b2-b771-480a-8ca3-4d4c28469aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = str(1)\n",
    "num = str(2)\n",
    "# num = str(3)\n",
    "# num = str(4)\n",
    "# num = str(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c503f190-ea13-4c02-b1c5-8d3eee5a74ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "en_model = BertModel.from_pretrained('models/en_model')\n",
    "en_tokenizer = BertTokenizer.from_pretrained('models/en_tokenizer')\n",
    "bid2Gvec=read_bin('new_data/bid2Gvec.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9f8866e-5e0c-45b0-83a8-d498a9acad7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./models/cv2/ were not used when initializing Wav2Vec2ForPreTraining: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForPreTraining from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForPreTraining from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForPreTraining were not initialized from the model checkpoint at ./models/cv2/ and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from contextlib import redirect_stdout\n",
    "from transformers import Wav2Vec2ForPreTraining,Wav2Vec2FeatureExtractor\n",
    "\n",
    "with redirect_stdout(open(os.devnull, 'w')):#一時的に出力を無効化\n",
    "    path = \"./models/cv\"+str(num)+\"/\"\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(\"patrickvonplaten/wav2vec2-base-v2\")# Wav2Vec2Processor => Wav2Vec2FeatureExtractor\n",
    "    model = Wav2Vec2ForPreTraining.from_pretrained(path)# Wav2Vec2ForCTC => Wav2Vec2ForPreTraining\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4660d944-221c-49aa-b54f-d12f6c36e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_Search_topN_filechk(concat_vecs,input_v,file_path,i):\n",
    "    max_sim=dict()\n",
    "    c2 = 0\n",
    "        \n",
    "    for bid,v in concat_vecs:\n",
    "        print('\\r%d : %d / %d' %(i,c2, len(concat_vecs)), end='')\n",
    "        c2 =  c2 + 1\n",
    "        cos_sim_value = cos_sim(input_v,v)\n",
    "        \n",
    "        if bid not in max_sim:\n",
    "            max_sim[bid] = cos_sim_value\n",
    "        else:\n",
    "            if max_sim[bid] < cos_sim_value:\n",
    "                max_sim[bid] = cos_sim_value\n",
    "    save_bin(file_path,max_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41671efe-49cd-4c85-b087-57bd1c32c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_parquet('BirdModel_remove_test/data_cross-valid/test_'+num+'.parquet')#10293\n",
    "test_index = list(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefbb661-3ccd-422a-bf79-ba04922aeb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1838\n",
      "L\n",
      "32 : 21456 / 88152"
     ]
    }
   ],
   "source": [
    "print(len(test_index))\n",
    "for slg_i in range(5):\n",
    "    SLG = [(0,1,0),(0,0,1),(0,1,1),(1,0,1),(1,1,0),(1,1,1)\n",
    "    if_S,if_L,if_G = SLG[slg_i]\n",
    "\n",
    "    flg = \"\"\n",
    "    if if_S == 1:\n",
    "        flg += \"S\"\n",
    "    if if_L == 1:\n",
    "        flg += \"L\"\n",
    "    if if_G == 1:\n",
    "        flg += \"G\"\n",
    "    print(flg)\n",
    "    \n",
    "    input_vecs_list = read_bin(\"new_data_cv_SLG/input_vecs_list_\"+flg+\"_\"+num+\".bin\")\n",
    "    try:\n",
    "        os.makedirs('csv_cv_'+flg+'_'+num)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for i in range(len(test_index)):\n",
    "        idx = test_index[i]\n",
    "        file_path = 'csv_cv_'+flg+\"_\"+num+'/'+str(idx)+'.bin'\n",
    "        if not os.path.exists(file_path):\n",
    "            input_vecs = input_vecs_list[i]\n",
    "            multi_Search_topN_filechk(en_concat_vecs_et,input_vecs,file_path,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056d70ad-a0ed-4942-b9cc-9fa6e0da8030",
   "metadata": {},
   "source": [
    "## 結果のソート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ff8cbff-fa3a-46fb-8fe6-4e03a1b19277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prm = \"loss_1_10\"\n",
    "# prm = \"loss_1_100\"\n",
    "# prm = \"step_3_2\"\n",
    "# prm = \"step_3_2_norm\"\n",
    "prm = \"cv\"+num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14457a55-dc54-4edb-b77b-7159fa4c30db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_bin(filename,data):\n",
    "    with open(filename,'wb') as bf:\n",
    "        pickle.dump(data,bf)\n",
    "\n",
    "def read_bin(filename):\n",
    "    with open(filename,'rb') as bf:\n",
    "        bin_data = pickle.load(bf)\n",
    "    return bin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55562694-ac3b-463d-82f3-837fe5243c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# test_index = list(test.index)\n",
    "# del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "155406b2-6aa3-4c0f-afda-fa42386ed33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not p\n",
    "data_sorted = []\n",
    "\n",
    "for idx in test_index:\n",
    "    data = read_bin('csv_cv'+num+'/'+str(idx)+'.bin')\n",
    "    data_sorted.append(dict(sorted(data.items(), key=lambda item: item[1],reverse=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cf60a81-cd24-4b7b-a134-49b35d3e3f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bin('csv_cv'+num+'/data_sorted_'+prm+'.bin',data_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5ea7e2b-8438-436f-9901-2d4848dd0d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_l = []\n",
    "# for i in range(20):\n",
    "#     all_l.append(list(data_sorted[i].keys()))\n",
    "#     all_l.append(list(data_sorted[i].values()))\n",
    "    \n",
    "# import pandas as pd\n",
    "\n",
    "# today = \"0729\"\n",
    "# df = pd.DataFrame(all_l)\n",
    "# df.to_csv('output/output_'+today+'_'+prm+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab9595c-b912-4e3c-b3f7-87e83d617cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p\n",
    "data_p_sorted = []\n",
    "\n",
    "for idx in test_index:\n",
    "    data_p = read_bin('csv_p/'+str(idx)+'.bin')\n",
    "    # data_p = read_bin('csv_cv'+prm+'_p/'+str(idx)+'.bin')\n",
    "    print(idx)\n",
    "    data_p_sorted.append(dict(sorted(data_p.items(), key=lambda item: item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74951875-7bf4-4112-8267-dd2288aa44af",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bin('csv_cv'+num+'_p/data_p_sorted_'+prm+'.bin',data_p_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0078f380-d18b-4e5e-936e-94626b3e3dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_l = []\n",
    "# for i in range(20):\n",
    "#     all_l.append(list(data_p_sorted[i].keys()))\n",
    "#     all_l.append(list(data_p_sorted[i].values()))\n",
    "    \n",
    "# import pandas as pd\n",
    "\n",
    "# today = \"0714\"\n",
    "# df = pd.DataFrame(all_l)\n",
    "# # df.to_csv('output_p_'+today+'_'+prm+'.csv', index=False)\n",
    "# df.to_csv('output/output_p_'+today+'_'+prm+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e35de-68af-4370-8aae-492d2a4986db",
   "metadata": {},
   "source": [
    "## 検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "af6eb882-5f24-4fc7-a886-0c5c54cdf482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prmは一つ上のセクションにて定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3096b0c6-b344-4a0f-a99d-a3a73253e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_sorted = read_bin('csv_cv'+prm+'/data_sorted_'+prm+'.bin')\n",
    "# data_sorted = read_bin('csv_cv'+prm+'_p/data_p_sorted_'+prm+'.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "30f443a7-2428-4049-b7c3-30213fe5f459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_sorted[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6375ba62-d0f0-43ed-8688-e452fe833fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sorted_id = []\n",
    "data_sorted_sim = []\n",
    "\n",
    "for d in data_sorted:\n",
    "    data_sorted_id.append(list(d.keys())[:400])\n",
    "    data_sorted_sim.append(list(d.values())[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5ca0d9e7-9bfb-4519-a4a7-2a2e46274f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05552816789009378,\n",
       " 0.05483066575735448,\n",
       " 0.05449225043376088,\n",
       " 0.054418008033872,\n",
       " 0.05427616965235937,\n",
       " 0.0539751159009753,\n",
       " 0.05388954977586201,\n",
       " 0.053651935039797,\n",
       " 0.05348710437880466,\n",
       " 0.0534708726473036]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sorted_sim[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b1953ccb-abcb-4d9b-87ca-200021a0c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology = read_bin(\"new_data/ontology.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "feb93c3c-e4f7-4b49-baaf-4af9d4fb0163",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_d = dict()\n",
    "\n",
    "for d in ontology:\n",
    "    ontology_d[d[\"id\"]]=d\n",
    "\n",
    "del ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e4ba30b9-a336-48b1-bc31-d870096fb694",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sorted_name_en = []\n",
    "data_sorted_name_ja = []\n",
    "\n",
    "for id_l in data_sorted_id:\n",
    "    en_l = []\n",
    "    ja_l = []\n",
    "    for a_id in id_l:\n",
    "        d = ontology_d[a_id]\n",
    "        en = \"\"\n",
    "        ja = \"\"\n",
    "        \n",
    "        if d[\"en_name\"] != None:\n",
    "            en = d[\"en_name\"]\n",
    "        if d[\"ja_name\"] != None:\n",
    "            ja = d[\"ja_name\"]\n",
    "            \n",
    "        if d[\"en_aliases\"] != {}:\n",
    "            en = en + ' | '+' | '.join(list(d[\"en_aliases\"].values()))\n",
    "            \n",
    "        if d[\"ja_aliases\"] != {}:\n",
    "            ja = ja + ' | '+' | '.join(list(d[\"ja_aliases\"].values()))\n",
    "            \n",
    "        en_l.append(en)\n",
    "        ja_l.append(ja)\n",
    "        \n",
    "    data_sorted_name_en.append(en_l)\n",
    "    data_sorted_name_ja.append(ja_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "03451032-2e07-4e84-ad47-5163466d5443",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_l = []\n",
    "for i in range(20):\n",
    "    all_l.append(data_sorted_name_en[i])\n",
    "    all_l.append(data_sorted_name_ja[i])\n",
    "    all_l.append(data_sorted_id[i])\n",
    "    all_l.append(data_sorted_sim[i])\n",
    "    all_l.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "61497f67-c9ec-4963-9ff8-1bbce785de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_l)\n",
    "df.to_csv('output_'+prm+'.csv', index=False)\n",
    "# df.to_csv('output_p_'+prm+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "aca0f144-394c-4eb6-99e3-7861aa49feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(20):\n",
    "#     for j in range(15):\n",
    "#         print(data_sorted_id[j][i],end=\" \")\n",
    "#     print()\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00287862-6d38-4945-91ed-5a9c7cca2ae6",
   "metadata": {},
   "source": [
    "## hit@k and MRR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9835aa1-0b41-4572-82a0-0c558eb5794a",
   "metadata": {},
   "source": [
    "検索結果の読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c28db3d7-e74a-4fd9-a717-62394fe44fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prmは２つ上のセクションにて定義済み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f20edff7-a704-420c-b710-cf7b6cc575b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sorted = read_bin('csv/data_sorted_'+prm+'.bin')\n",
    "# data_sorted_p = read_bin('csv_p/data_p_sorted_'+prm+'.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fffd69ab-5caa-4659-91d1-3c1dd17dbda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_id(data_sorted):\n",
    "    data_sorted_id = []\n",
    "    for d in data_sorted:\n",
    "        data_sorted_id.append(list(d.keys())[:400])\n",
    "    return data_sorted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6a3691eb-61db-4a04-ace1-3ce0317eb423",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_sorted = get_sorted_id(data_sorted)\n",
    "# id_sorted_p = get_sorted_id(data_sorted_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7aa8fe90-0406-4b50-b5be-ea0117634281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del data_sorted\n",
    "# del data_sorted_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b73fb2b-2981-420c-8829-b3e471436919",
   "metadata": {},
   "source": [
    "正解文書"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5eeda053-3267-4448-bbd0-42f3b8593854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20件\n",
    "test_ans = [\"Q195518\",\"Q2669182\",\"Q1589896\",\"Q25700\",\"Q1074291\",\"Q27075595\",\"Q235152\",\"Q1272534\",\"Q1074163\",\"Q1270171\",\"Q1071547\",\"Q177798\",\"Q493173\",\"Q26650\",\"Q495144\",\"Q195518\",\"Q1034960\",\"Q890912\",\"Q184820\",\"Q862812\"]\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2d134b-e046-405d-b8bd-b2d2bd7dac91",
   "metadata": {},
   "source": [
    "検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "505461f3-cbc8-4819-8413-cc79b0f7d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranks(id_sorted):\n",
    "    ranks = []\n",
    "    for i in range(20):\n",
    "        if test_ans[i] in id_sorted[i]:\n",
    "            index = id_sorted[i].index(test_ans[i])\n",
    "            ranks.append(index+1)\n",
    "        else:\n",
    "            ranks.append(-1)\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9356d023-a802-431f-b81c-d81ace373a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_sorted\n",
    "# id_sorted_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "81dda3e0-d30a-4aa7-96bf-1a0f7ab9047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ranks = ranks(id_sorted)\n",
    "# result_ranks_p = ranks(id_sorted_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5ba664e4-fe34-45c4-9c84-54df737d3593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 59 191 227 211 132 400 150 87 126 73 38 86 96 204 141 58 20 285 195\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(map(str, result_ranks)))\n",
    "# print(\" \".join(map(str, result_ranks_p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "855763e6-6bdd-44be-8c66-3ca6a2b18406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mrr(ranks):\n",
    "    reciprocal_ranks = [1 / (rank + 1) for rank in ranks]\n",
    "    mrr = sum(reciprocal_ranks) / len(ranks)\n",
    "    print(mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "576cb0e5-2e8d-4f75-be51-a9bbbec61001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011015160092636093\n"
     ]
    }
   ],
   "source": [
    "calculate_mrr(result_ranks)\n",
    "# calculate_mrr(result_ranks_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e2a0b-69be-4b46-87e8-f486955f87b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prm = \"step_3_2\"\n",
    "\n",
    "    # 112 73 144 201 233 46 400 175 46 112 66 55 103 129 192 98 26 28 244 182\n",
    "    # 320 258 400 345 400 224 400 400 326 400 400 400 195 400 296 400 244 223 176 46\n",
    "\n",
    "    # 0.012225021479883039\n",
    "    # 0.004187707828634603\n",
    "\n",
    "# prm = \"step_3_2_norm\"\n",
    "\n",
    "    # 134 59 191 227 211 132 400 150 87 126 73 38 86 96 204 141 58 20 285 195\n",
    "\n",
    "    # 0.011015160092636093"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd3523d-8134-4b4e-a8a4-a1e45b894a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音声の何パーセントがなくなっているのかは"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368255f8-2085-465a-9f1c-ddecccf06469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムシャッフルした検索順位での比較実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ef7480-4ae9-4df7-bb2b-75d3e3d6a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5180dc85-b7b8-45aa-87d5-e848189208f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.12以上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7678d5c2-45dd-4ad8-a673-a6f2b0e83a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setp数はシャッフルのあと\n",
    "# それよりは"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23a6a86-bad2-488a-be3f-fc201d10efc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20%でテスト（5ホールド前提）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357205a8-5327-46c3-93dc-aaf6e6f5fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# クロスバリデーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8765ecd-c6a4-4789-a8e0-918e0b40ebf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
